{"cells":[{"source":" ! pip install faiss-cpu\n ! pip install sentence-transformers","metadata":{"executionCancelledAt":null,"executionTime":11318,"lastExecutedAt":1715938552749,"lastExecutedByKernel":"56a34db2-4398-4bca-97e1-69d276c8e9d7","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":" ! pip install faiss-cpu\n ! pip install sentence-transformers","outputsMetadata":{"0":{"height":616,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"cell_type":"code","id":"1f9da8e4-efb9-4129-872b-5a967761bcce","outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nCollecting faiss-cpu\n  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\nDownloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: faiss-cpu\nSuccessfully installed faiss-cpu-1.8.0\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (2.5.1)\nRequirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.38.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.2)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.2.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.26.4)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.4.1.post1)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.21.4)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (10.2.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.2.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.10.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.0)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.19.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\nRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.2.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.4.99)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"}],"execution_count":2},{"source":"# Cleaning the titles of a csv file","metadata":{},"cell_type":"markdown","id":"a5b37148-01c9-4863-a514-7724b4f5b80a"},{"source":"from sentence_transformers import SentenceTransformer\nimport pandas as pd\nimport faiss\nimport numpy as np\n\n# Load the reference dataset from a CSV file\nreference_data = pd.read_csv('all_titles.csv')\n\n# Create a DataFrame with specific columns from the reference dataset\n# This DataFrame contains original titles and their cleaned versions\nreference_df = pd.DataFrame(reference_data, columns=['Title', 'Cleaned_Title'])\n\n# Load the dirty dataset from a CSV file\n# This dataset contains titles that may need cleaning or standardization\ndirty_data = pd.read_csv('Insurance.csv')\n\n# Convert the 'Title' column to a list of strings from the dirty dataset\n# These titles will be processed to find their cleaned versions\ndirty_titles = dirty_data['Title'].astype(str).tolist()\n\n# Initialize the sentence transformer model for encoding text\n# This model converts titles into numerical vectors for comparison\nencoder = SentenceTransformer(\"paraphrase-mpnet-base-v2\")\n\n# Encode the titles from the reference dataset into vectors\n# These vectors represent the semantic meaning of the titles\nvectors_reference = encoder.encode(reference_df['Title'].tolist())\n\n# Get the dimensionality of the vectors\n# This is needed to create a FAISS index with the correct dimensions\nvector_dimension = vectors_reference.shape[1]\n\n# Create a FAISS index for L2 distance (Euclidean distance) for the reference dataset\n# This index allows efficient similarity searches between vectors\nindex_reference = faiss.IndexFlatL2(vector_dimension)\n\n# Convert vectors to float32 for compatibility with FAISS, then normalize them\n# Normalization ensures that the distance calculations are scale-invariant\nvectors_reference = vectors_reference.astype(np.float32)\nfaiss.normalize_L2(vectors_reference)\n\n# Add the normalized vectors to the FAISS index\n# This step prepares the index for querying\nindex_reference.add(vectors_reference)\n\n# Encode the titles from the dirty dataset into vectors\n# Similar to the reference dataset, these vectors will be used for searching\nvectors_dirty = encoder.encode(dirty_titles)\n\n# Ensure the dirty vectors are of type float32 and normalize them\n# This ensures compatibility and effectiveness of distance calculations\nvectors_dirty = vectors_dirty.astype(np.float32)\nfaiss.normalize_L2(vectors_dirty)\n\n# Number of nearest neighbors to find\n# k=1 means we are looking for the closest match in the reference dataset\nk = 1\n\n# Perform the search for each title in the dirty dataset against the reference dataset\n# This loop finds the closest reference title for each dirty title\nann_results = []\nfor vector in vectors_dirty:\n    distances, indices = index_reference.search(vector.reshape(1, -1), k=k)\n    ann_results.append((indices[0][0], distances[0][0]))\n\n# Create a DataFrame with the ANN results\n# This DataFrame contains indices of the closest matches and their distances\nann_df = pd.DataFrame(ann_results, columns=['ann', 'distance'])\n\n# Add the 'Cleaned_Title' from the reference dataset to the ANN results\n# This step retrieves the cleaned title for each dirty title based on the closest match\nann_df['Cleaned_Title'] = ann_df['ann'].apply(lambda idx: reference_df.iloc[idx]['Cleaned_Title'])\n\n# Merge the ANN results with the original dirty DataFrame to get the titles\n# This allows us to compare the original and cleaned titles side by side\nmerged_df = pd.merge(ann_df, dirty_data, left_index=True, right_index=True)\n\n# Display the top results\n# This shows the original titles, their cleaned versions, and the distance of the match\nmerged_df[['Title', 'Cleaned_Title', 'distance']].value_counts()","metadata":{"executionCancelledAt":null,"executionTime":75749,"lastExecutedAt":1715938628500,"lastExecutedByKernel":"56a34db2-4398-4bca-97e1-69d276c8e9d7","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from sentence_transformers import SentenceTransformer\nimport pandas as pd\nimport faiss\nimport numpy as np\n\n# Load the reference dataset from a CSV file\nreference_data = pd.read_csv('all_titles.csv')\n\n# Create a DataFrame with specific columns from the reference dataset\n# This DataFrame contains original titles and their cleaned versions\nreference_df = pd.DataFrame(reference_data, columns=['Title', 'Cleaned_Title'])\n\n# Load the dirty dataset from a CSV file\n# This dataset contains titles that may need cleaning or standardization\ndirty_data = pd.read_csv('Insurance.csv')\n\n# Convert the 'Title' column to a list of strings from the dirty dataset\n# These titles will be processed to find their cleaned versions\ndirty_titles = dirty_data['Title'].astype(str).tolist()\n\n# Initialize the sentence transformer model for encoding text\n# This model converts titles into numerical vectors for comparison\nencoder = SentenceTransformer(\"paraphrase-mpnet-base-v2\")\n\n# Encode the titles from the reference dataset into vectors\n# These vectors represent the semantic meaning of the titles\nvectors_reference = encoder.encode(reference_df['Title'].tolist())\n\n# Get the dimensionality of the vectors\n# This is needed to create a FAISS index with the correct dimensions\nvector_dimension = vectors_reference.shape[1]\n\n# Create a FAISS index for L2 distance (Euclidean distance) for the reference dataset\n# This index allows efficient similarity searches between vectors\nindex_reference = faiss.IndexFlatL2(vector_dimension)\n\n# Convert vectors to float32 for compatibility with FAISS, then normalize them\n# Normalization ensures that the distance calculations are scale-invariant\nvectors_reference = vectors_reference.astype(np.float32)\nfaiss.normalize_L2(vectors_reference)\n\n# Add the normalized vectors to the FAISS index\n# This step prepares the index for querying\nindex_reference.add(vectors_reference)\n\n# Encode the titles from the dirty dataset into vectors\n# Similar to the reference dataset, these vectors will be used for searching\nvectors_dirty = encoder.encode(dirty_titles)\n\n# Ensure the dirty vectors are of type float32 and normalize them\n# This ensures compatibility and effectiveness of distance calculations\nvectors_dirty = vectors_dirty.astype(np.float32)\nfaiss.normalize_L2(vectors_dirty)\n\n# Number of nearest neighbors to find\n# k=1 means we are looking for the closest match in the reference dataset\nk = 1\n\n# Perform the search for each title in the dirty dataset against the reference dataset\n# This loop finds the closest reference title for each dirty title\nann_results = []\nfor vector in vectors_dirty:\n    distances, indices = index_reference.search(vector.reshape(1, -1), k=k)\n    ann_results.append((indices[0][0], distances[0][0]))\n\n# Create a DataFrame with the ANN results\n# This DataFrame contains indices of the closest matches and their distances\nann_df = pd.DataFrame(ann_results, columns=['ann', 'distance'])\n\n# Add the 'Cleaned_Title' from the reference dataset to the ANN results\n# This step retrieves the cleaned title for each dirty title based on the closest match\nann_df['Cleaned_Title'] = ann_df['ann'].apply(lambda idx: reference_df.iloc[idx]['Cleaned_Title'])\n\n# Merge the ANN results with the original dirty DataFrame to get the titles\n# This allows us to compare the original and cleaned titles side by side\nmerged_df = pd.merge(ann_df, dirty_data, left_index=True, right_index=True)\n\n# Display the top results\n# This shows the original titles, their cleaned versions, and the distance of the match\nmerged_df[['Title', 'Cleaned_Title', 'distance']].value_counts()","outputsMetadata":{"0":{"height":321,"type":"dataFrame"},"11":{"height":321,"type":"dataFrame"}}},"cell_type":"code","id":"4d368d58-bd34-4905-b273-0a7fe8b81071","outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e28741b9d303452fbd96cf9b8cd94cfe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40b220963dd6472d9523d3b4c11a3af3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/3.73k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c582e059afb460d8e840e669f5ef60d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ed7632080574111ba0d8f71237af70a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/594 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4911fdf6a7934ddaabf0796539e84d17"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad8d9c48d8784e628d7acb8e84ad29cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3cd5d4a21cd44930b07778fb25d801a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75dbd8945ac94f718e1da4248ffd55df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0d5f7a01c5c483e8e8d53a8fc4e5971"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6d97cb315f14747ab47a61a946e752b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdc5c8fd8c844dda912dfea5edcb4d8b"}},"metadata":{}},{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"Title","type":"string"},{"name":"Cleaned_Title","type":"string"},{"name":"distance","type":"number"},{"name":"count","type":"integer"}],"primaryKey":["Title","Cleaned_Title","distance"],"pandas_version":"1.4.0"},"data":{"Title":["Chief Executive Officer","Chief Executive Officer","CEO","Chief Operating Officer","Founder","Chief Operating Officer","Co-Founder","CEO","Founder","Founder & CEO","Chief Executive Officer","Founding Director","Founder & CEO","Founder and Managing Director","Co-Founder","Founding Partner","Group CEO","Founder & Managing Director","Founder and CEO","COO","Group Chief Executive Officer","CEO & Co-Founder","Chief Operations Officer","CEO and Founder","Co-Founder & CEO","COO","Founder & Director","Chief Operating Officer","Co-Founder & Director","CEO/Founder","Group Chief Operating Officer","CEO and Founder","Founder","Co-founder and CEO","Co-Founder & COO","Founder and CEO","Chief Operations Officer","Chairman & COO","Co-Founder & Executive Director","Co-Founder & Managing Director","Co Founder","Founder / Chief Executive Officer","Co Founder & Managing Director","Founder / Director","Founder & Financial Adviser","CEO & Founder","CEO / Founder","Co-Founder and CTO","Director & Co-Founder","Founding Director, COO & CTO","Co-founder & CPO","Managing Director & Founder","Director at 24|7 Home Rescue & CEO","Founder / CEO","Founder - Group Chief Underwriting Officer","Founder & Chief Investment Officer","Founder & Chief Ideas Officer","Founder & Chief Digital Officer","Founder / CEO","Founder & Chartered Independent Financial Adviser","FD & Chief Operating Officer","Founder & CEO of Rnwl, Founder","Director Founder","Founder & Adviser","Financial Director and Mortgage & Protection Consultant","Director / Co Founder","Former Chief Executive Officer","Founder / Managing Director","Director & Founder","Founder & Chief Rooster","Founder & Senior Adviser","Founder & Editor","Distribution Director and Co-Founder","Founder & Editor, Assured Intelligence and Co-founder at Assured","Founder & Director of Insurance","Founder & Engagement Lead","Director at iam|INSURED Online and CoFounder","Founder Director","Director and co founder","Founder & Executive Director","Founder & Leader","Director and Founder","Founder & Managing D","Director and Founder of new Lloyd's Brokers","Founder & Managing Director - M & M Group","Founder & Managing Director l Chartered Insurance Broker","Founder & Non-Executive Director","Founder & Company Director","Founder & Chief Visionary Officer","Director and founding co-shareholder","Accelerating growth in Private Equity backed ventures, CFO - COO","Founder Insurance Broker Innovative Corporate Solutions Niche","Founder MD @ PORTABL.co | Digital insurance & financial services || Advisor: TURNTABL.io > Remote (Ghana!) software engineering talent on tap >> inspired by the future","MD and founding partner A&B Insurance Brokers ( part","Managing Director & Co-Founder","Managing Director - Founder","Managing Director / CEO","Managing Director / Co-founder","Managing Director and Co Founder","Managing Director/Founder","Office Manager/PA to CEO","Owner and founder","PA to CEO & Board","PA to CEO /Office Manager","PA to Joint CEO","Partner - CEO","President & CEO","President & Chief Operating Officer","President and CEO","Principal CEO","Private Medical Insurance & Protection Specialist and Founder","Product Director/Co-Founder","Protection Specialist and Founding Director","Senior Frontend Developer at Ignite Software Systems. Founder","UK COO","ceo","chief operating officer","md ceo","Joint CEO","Interim Chief Executive Officer","Group Chief Executive Officer & Chief Underwriting Officer","Founder and Principal Consultant","Founder and Chairman","Founder and Chartered Financial Planner","Founder and Chief Commercial Officer","Founder and Chief Operating Officer","Founder and Commercial Director","Founder and Director of FOMO Mortgages","Director & CEO","Founder and Group CEO","Founder and IFA","Founder and Mortgage & Protection Advisor","Founder and Mortgage Broker","Founder and Senior Partner","Group CEO - WillU Financial Group","Founder at Ballantyne Brokers Limited","Founder | MD","Founder, CEO","Founder, Owner & Managing Director","Founder, Owner & Managing Director at Leadenhall Insurance Brokers Ltd","Founder, Shareholder and Director","Founder. Chief Underwriting Officer and Executive Director.","Founder/Director at Vita Risk Solutions","Founder/Group CFO","Founding Director & CEO","Founding Partner of Vizion Health","Founder and Executive Director","Co-founder & Executive Chairman","Deputy Chief Operating Officer","CEO and co-founder","CEO | Co Founder","CEO, and Founder","CEO/Managing Director","CEO/President","CFO & Co-Founder","COO & Co-founder","COO & In-House Counsel","CTO & Co-founder","CTO and Co-founder","CUO & Founder","Chair & Founder/Owner","Chairman & Founder","Chairman at Kay International PLC & Co-Founder","Chief Executive Officer & Founder","Chief Executive Officer Fennech Pte Ltd","Chief Executive Officer and Sustainability Officer","Chief Executive Officer, Active Underwriter","Chief Finance and Operating Officer","Chief Finance and Operations Officer","Chief Financial Officer Operations","Chief Financial and Operating Officer","Chief Operating Officer & Partner","Chief Operating Officer Portfolio Risks Europe","Chief Operating Officer and Managing Director Pharmacy Insurance","Chief Operating Officer for France, Spain, Germany & Italy","CEO at Ventis","CEO and Managing Director","Chief Operations Officer / Chief People Officer","CEO and Head of Asset Management Underwriting","Business Manager, UK CEO Office","Business Owner & Founder","CEO & Chief Underwiting officer","CEO & Chief Underwriting Officer","CEO & Director of Business Development","CEO & Founder","CEO & Managing Partner","CEO + Founder","CEO - Acrisure London Wholesale","CEO - Broking","CEO - Consultancy","CEO - Founder","CEO - Founder","CEO - MGA","CEO - Retail","CEO Alchemy Underwriting Ltd.","CEO Alchemy Underwriting PI","CEO Blink Parametric","CEO Citadel Risk Group","CEO Director","CEO EA at Marco Capital","CEO International & Group Managing Director","CEO Property Services","CEO and Chairperson BABTAC &CIBTAC","CEO and Co-owner","Chief Operating Officer/Strategic Business Analytics","Co CEO","Commercial Director & Co-Founder","Co-Founder and Chief Technical Officer","Co-Founder and Director","Co-Founder and Head of Commercial","Co-Founder, Chief Technology Officer","Co-Founder, Chief Underwriting Officer","Co-Founder, Partner","Co-Founder, Vice President, and Treasurer","Co-Founder/Head Of Operations","Co-Founder/Specialist Advisor","Co-Founding Director","Co-founder","Co-founder & CEO","Co-founder & CTO","Acting COO & Head of Underwriting","Co-founder & business owner | Director | Head of Operations, HR & Finance","Co-founder - Chairman","Co-founder and CPTO","Co-founder and CTO","Co-founder and Director","Co-founder and Head of Underwriting","Co-founder and Managing Director","Co-founder, CEO","Co-founder, General Manager and Personal Travel Consultant","Cofounder and COO","Cofounder, CEO","Commercial COO","Co-Founder and Chief Underwriting Officer","Co-Founder and Chief Product Officer","Co Founder & CEO","Co-Founder and Chief Marketing Officer","Co Founder & CTO","Co Founder - Corporate Development Director","Co Founder, Product Development Lead","Co Founder/Director","Co Owner, Founder, Director","Co-CEO","Co-Chief Executive Officer","Co-Founder & Actuarial Director","Co-Founder & Business Development Director","Co-Founder & CTO","Co-Founder & CUO","Co-Founder & Chief Operating Officer","Co-Founder & Chief Product Officer","Co-Founder & Innovation Director","Co-Founder & Mortgage Adviser","Co-Founder & Operations Director","Co-Founder & Producer","Co-Founder / Chief Product Officer","Co-Founder / Director","Co-Founder / Operations Director","Co-Founder Architect","Co-Founder and CEO","Co-Founder and CFO","Co-Founder and COO","Co-Founder and CUO at Amphitrite Underwriting Limited","☂️ Technical Co-Founder"],"Cleaned_Title":["CEO","CEO","CEO","COO","Founder","COO","Co-Founder","CEO","Founder","Founder","CEO","Founding Director","Founder","Founder","Co-Founder","Founding Partner","CEO","Founder","Founder","COO","CEO","Co-Founder","COO","Founder","Co-Founder","COO","Founder","COO","Co-Founder","Founder","COO","Founder","Founder","Co-Founder","Co-Founder","Founder","COO","Chairman","Co-Founder","Co-Founder","Co-Founder","Founder","Co-Founder","Founder","Founder","Founder","Founder","Co-Founder","Co-Founder","Founding Director, COO and CTO","Co-Founder","Founder","CEO","Founder","Founder","Founder","Founder","Founder","Founder","Founder","COO","Founder","Founder","Co-Founder","Founder","Co-Founder","CEO","Founder","Founder","Founder","Founder","Founder","Co-Founder","Founder","Founder","Founder","Co-Founder","Founder","Co-Founder","Founder","Founder","Founder","Founder","Founder","Founder","Founder","Founder","Founder","Founder","Founder","CFO and COO","Founder","Founder","Founding Partner","Co-Founder","Founder","CEO","Co-Founder","Co-Founder","Founder","PA to CEO","Founder","PA to CEO","PA to CEO","PA to CEO","CEO","CEO","President","CEO","CEO","Founder","Co-Founder","Founding Director","Founder","COO","CEO","COO","CEO","CEO","CEO","Chief Executive Officer","Founder","Founder","Founder","Founder","Founder","Founder","Founder","CEO","Founder","Founder","Founder","Founder","Founder","CEO","Founder","Founder","Founder","Founder","Founder","Founder","Founder","Founder","Founder","Founder","Founding Partner","Founder","Co-Founder","COO","Co-Founder","Co-Founder","Founder","CEO","CEO","Co-Founder","Co-Founder","COO","Co-Founder","Co-Founder","Founder","Founder","Founder","Co-Founder","Founder","CEO","CEO","Founder","COO","COO","CFO","COO","COO","Chief Operating Officer","COO","COO","CEO","CEO","COO and CPO","CEO","CEO","Founder","Chief Executive Officer","Chief Executive Officer","CEO","Founder","CEO","Founder","CEO","CEO","CEO","Founder","Founder","CEO","CEO","CEO","CEO","CEO","CEO","CEO","CEO","CEO","CEO","Chairman","CEO","COO","CEO","Co-Founder","Co-Founder","Co-Founder","Co-Founder","Co-Founder","Co-Founder","Co-Founder","Co-Founder","Co-Founder","Co-Founder","Co-Founding Director","Co-Founder","Co-Founder","Co-Founder","Acting COO and Head of Underwriting","Co-Founder","Co-Founder","Co-Founder","Co-Founder","Co-Founder","Co-Founder","Co-Founder","Co-Founder","Co-Founder","Co-Founder","Co-Founder","COO","Co-Founder","Co-Founder","Co-Founder","Co-Founder","Co-Founder","Co-Founder","Co-Founder","Co-Founder","Founder","CEO","CEO","Founder","Co-Founder","Co-Founder","Co-Founder","Co-Founder","Co-Founder","Co-Founder","Co-Founder","Co-Founder","Co-Founder","Co-Founder","Co-Founder","Co-Founder","Co-Founder","Co-Founder","Co-Founder","Co-Founder","Co-Founder","Co-Founder"],"distance":[0,0,0,0,0,0,0,0,0,0,0,0,0,0.0865142494,0,0,0.3586013615,0.0830871314,0.0213246364,0,0.2551010847,0,0.1325579882,0.0551589429,0.0404717773,0,0.018975582,0,0.1609273851,0.0566911399,0.2389303297,0.0551589727,0,0.0248385891,0.1273076832,0.0213246197,0.1325580478,0,0.1946166456,0.0716173947,0,0.1092103273,0.0806053132,0.0482189879,0.1756951362,0.0554139242,0.0566911399,0.2370423973,0.0630476922,0,0.2665153146,0.028721042,0,0.0224658735,0,0.2971996665,0.5034022331,0,0.0224658698,0.2226047218,0.3656202257,0.6565071344,0,0.2446126938,0.2774392962,0,0.345795095,0.0566726401,0.1082257777,0.8791059852,0.2307261825,0.5021887422,0,0,0.3801081181,0.5714466572,0,0,0.0435428247,0.1283112615,0.3842660487,0.0784599483,0,0.6089801192,0,0,0,0.2001249492,0.2645530701,0.3088618517,0,0,0.6850525141,0,0,0.0343094021,0,0,0.0199042615,0,0,0.2688418925,0,0,0,0.320379436,0.0592650324,0.2380530238,0.0267432313,0.3862161934,0.673848629,0,0,0,0.4890542626,0,0,0.5637457967,0.2843454778,0.2016792893,0,0,0.2294262052,0,0,0,0,0,0.1656079441,0.141233772,0.7269563675,0,0,0,0,0.7229834795,0.5872905254,0,0.1610207111,0,0.3115940988,0,0,0,0.2134222686,0.8102586865,0.1025329679,0.1498406827,0.2592602372,0,0,0.1031387672,0.0458504185,0,0,0.1571665704,0,0.2602336109,0.3013243675,0,0.4053276181,0.2677195668,0,0.1481081545,0.7291460037,0,0.366961658,0,0.0404666662,0.1599783599,0.0890099704,0.249976784,0,0,0.6457474828,0,0.0818066373,0,0,0,0.3265895844,0.529111743,0.1755500883,0,0.0554139204,0.1611812711,0.1233768761,0,0.5298597813,0.5306860209,0.0498536341,0.0498536751,0.6391373873,0,0.5633468628,0.694778204,0.9546533823,0,0,0,0,0.6304100752,0.7714817524,0,0,0.1132966951,0,0.2814071178,0.1460685879,0,0.2729083002,0,0.225578621,0.3464595675,0.0638303757,0,0,0,0.0404717773,0.2332301587,0,0.3277236223,0.1572903991,0.5234915018,0.2370423973,0.1460685879,0.0629076138,0.0722661763,0,0,0.1728264689,0,0.4931542575,0,0.1624301821,0.0592866205,0.2016099244,0.2245928645,0,0.1671868265,0.0990433693,0,0,0.16677396,0.5711604357,0.1470021605,0.2332301587,0,0,0.1529503763,0.313275218,0,0,0.3697033823,0.1560741663,0.1269341111,0,0.4777104259,0.0248385891,0.0676223934,0.1254323721,0,0.3701216877],"count":[82,60,56,37,32,31,29,21,19,14,11,10,10,9,8,8,8,8,6,6,5,5,4,4,4,4,4,4,4,3,3,3,3,3,3,3,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]}},"total_rows":263,"truncation_type":null},"text/plain":"Title                                                  Cleaned_Title  distance    \nChief Executive Officer                                CEO            2.192104e-13    82\n                                                                      2.098326e-13    60\nCEO                                                    CEO            2.877439e-13    56\nChief Operating Officer                                COO            2.683821e-13    37\nFounder                                                Founder        3.178171e-13    32\n                                                                                      ..\nCo-Founder and CEO                                     Co-Founder     2.483859e-02     1\nCo-Founder and CFO                                     Co-Founder     6.762239e-02     1\nCo-Founder and COO                                     Co-Founder     1.254324e-01     1\nCo-Founder and CUO at Amphitrite Underwriting Limited  Co-Founder     0.000000e+00     1\n☂️ Technical Co-Founder                                Co-Founder     3.701217e-01     1\nName: count, Length: 263, dtype: int64"},"metadata":{},"execution_count":3}],"execution_count":3},{"source":"# Cleaning a Single Title with IndexFlatL2","metadata":{},"cell_type":"markdown","id":"0d642667-b9c3-4e9a-b038-627f4fc44e9e"},{"source":"from sentence_transformers import SentenceTransformer\nimport pandas as pd\nimport faiss\nimport numpy as np\n\n# Load dataset from a CSV file\ndata = pd.read_csv('all_titles.csv')","metadata":{"executionCancelledAt":null,"executionTime":843,"lastExecutedAt":1715938629345,"lastExecutedByKernel":"56a34db2-4398-4bca-97e1-69d276c8e9d7","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from sentence_transformers import SentenceTransformer\nimport pandas as pd\nimport faiss\nimport numpy as np\n\n# Load dataset from a CSV file\ndata = pd.read_csv('all_titles.csv')"},"cell_type":"code","id":"1fa9cde9-851a-4711-91da-d2533502371f","outputs":[],"execution_count":4},{"source":"# Create a DataFrame with specific columns from the dataset\ndf = pd.DataFrame(data, columns=['Title', 'Cleaned_Title'])\n\n# Convert the 'Title' column to a list of strings\ntitle = df['Title'].astype(str).tolist()\n\n# Initialize the sentence transformer model for encoding text\n# This model is used to convert text into numerical vectors\nencoder = SentenceTransformer(\"paraphrase-mpnet-base-v2\")\n\n# Encode the titles into vectors\n# Each title is converted into a high-dimensional vector\nvectors = encoder.encode(title)\n\n# Get the dimensionality of the vectors\n# This is needed to create the FAISS index with the correct dimensions\nvector_dimension = vectors.shape[1]","metadata":{"executionCancelledAt":null,"executionTime":55409,"lastExecutedAt":1715939263417,"lastExecutedByKernel":"56a34db2-4398-4bca-97e1-69d276c8e9d7","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Create a DataFrame with specific columns from the dataset\ndf = pd.DataFrame(data, columns=['Title', 'Cleaned_Title'])\n\n# Convert the 'Title' column to a list of strings\ntitle = df['Title'].astype(str).tolist()\n\n# Initialize the sentence transformer model for encoding text\n# This model is used to convert text into numerical vectors\nencoder = SentenceTransformer(\"paraphrase-mpnet-base-v2\")\n\n# Encode the titles into vectors\n# Each title is converted into a high-dimensional vector\nvectors = encoder.encode(title)\n\n# Get the dimensionality of the vectors\n# This is needed to create the FAISS index with the correct dimensions\nvector_dimension = vectors.shape[1]"},"cell_type":"code","id":"23c427a7-a121-43fe-93cc-d310424edadc","outputs":[],"execution_count":19},{"source":"\n# Create a FAISS index for L2 distance (Euclidean distance)\n# This index will allow us to perform efficient similarity searches\nindex = faiss.IndexFlatL2(vector_dimension)\n\n# Convert vectors to float32 for compatibility with FAISS, then normalize them\n# Normalization is important for distance calculations to be meaningful\nvectors = vectors.astype(np.float32)\nfaiss.normalize_L2(vectors)\n\n# Add the normalized vectors to the FAISS index\n# This step is necessary before performing any searches\nindex.add(vectors)\n\n# Define the search query\n# This is the text we want to find similar titles for\nsearch_text = 'Dimention director at XYZ'\n\n# Encode the search query into a vector\n# The query is also converted into a vector to perform the search\nsearch_vector = encoder.encode([search_text])\n\n# Ensure the search vector is of type float32 and normalize it\n# Similar to the title vectors, the query vector is also normalized\nsearch_vector = search_vector.astype(np.float32)\nfaiss.normalize_L2(search_vector.reshape(1, -1))\n\n# Number of nearest neighbors to find\n# This determines how many similar titles we want to retrieve\nk = 3\n\n# Perform the search\n# This returns the distances and indices of the k nearest neighbors\ndistances, ann = index.search(search_vector, k=k)\n\n# Create a DataFrame with the distances and indices of the nearest neighbors\n# This DataFrame is used to display the results in a readable format\nresults = pd.DataFrame({'distances': distances[0], 'ann': ann[0]})\n\n# Merge the results with the original DataFrame to get the titles of the nearest neighbors\n# This allows us to see the actual titles corresponding to the indices\nmerge = pd.merge(results, df, left_on='ann', right_index=True)\n\n# Display the top results\n# The results are sorted by distance, with the closest matches first\nmerge.head()","metadata":{"executionCancelledAt":null,"executionTime":168,"lastExecutedAt":1715939097585,"lastExecutedByKernel":"56a34db2-4398-4bca-97e1-69d276c8e9d7","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"\n# Create a FAISS index for L2 distance (Euclidean distance)\nindex = faiss.IndexFlatL2(vector_dimension)\n\n# Convert vectors to float32 for compatibility with FAISS, then normalize them\nvectors = vectors.astype(np.float32)\nfaiss.normalize_L2(vectors)\n\n# Add the normalized vectors to the FAISS index\nindex.add(vectors)\n\n# Define the search query\nsearch_text = 'Dimention director at XYZ'\n\n# Encode the search query into a vector\nsearch_vector = encoder.encode([search_text])\n\n# Ensure the search vector is of type float32 and normalize it\nsearch_vector = search_vector.astype(np.float32)\nfaiss.normalize_L2(search_vector.reshape(1, -1))\n\n# Number of nearest neighbors to find\nk = 3\n\n# Perform the search\ndistances, ann = index.search(search_vector, k=k)\n\n# Create a DataFrame with the distances and indices of the nearest neighbors\nresults = pd.DataFrame({'distances': distances[0], 'ann': ann[0]})\n\n# Merge the results with the original DataFrame to get the titles of the nearest neighbors\nmerge = pd.merge(results, df, left_on='ann', right_index=True)\n\n# Display the top results\nmerge.head()","outputsMetadata":{"0":{"height":146,"type":"dataFrame"},"11":{"height":171,"type":"dataFrame"}}},"cell_type":"code","id":"afbbd5e6-d4fa-4f2f-8d4f-d6c88a309063","outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"distances","type":"number"},{"name":"ann","type":"integer"},{"name":"Title","type":"string"},{"name":"Cleaned_Title","type":"string"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[0,1,2],"distances":[1.0814548731,1.1193313599,1.1229147911],"ann":[1592,209,1348],"Title":["Senior Vice President, Creator Peripherals","Division Operations Director","Director of DTC Operations"],"Cleaned_Title":["Sr. VP of Creator Peripherals","Division Operations Director","Director of DTC Operations"]}},"total_rows":3,"truncation_type":null},"text/plain":"   distances  ...                  Cleaned_Title\n0   1.081455  ...  Sr. VP of Creator Peripherals\n1   1.119331  ...   Division Operations Director\n2   1.122915  ...     Director of DTC Operations\n\n[3 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>distances</th>\n      <th>ann</th>\n      <th>Title</th>\n      <th>Cleaned_Title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.081455</td>\n      <td>1592</td>\n      <td>Senior Vice President, Creator Peripherals</td>\n      <td>Sr. VP of Creator Peripherals</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.119331</td>\n      <td>209</td>\n      <td>Division Operations Director</td>\n      <td>Division Operations Director</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.122915</td>\n      <td>1348</td>\n      <td>Director of DTC Operations</td>\n      <td>Director of DTC Operations</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":18}],"execution_count":18},{"source":"# Measuring and Comparing Speed ","metadata":{},"cell_type":"markdown","id":"539283c1-e141-47d9-a832-e46482896e84"},{"source":"## Measuring Speed with IndexFlatL2","metadata":{},"cell_type":"markdown","id":"b7edfc86-18bc-4e2b-89b3-404dd6c75f15"},{"source":"%%time\nD, I = index.search(search_vector, k)  # search\nprint(I)","metadata":{"executionCancelledAt":null,"executionTime":54,"lastExecutedAt":1715938683560,"lastExecutedByKernel":"56a34db2-4398-4bca-97e1-69d276c8e9d7","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"%%time\nD, I = index.search(search_vector, k)  # search\nprint(I)","outputsMetadata":{"0":{"height":80,"type":"stream"}}},"cell_type":"code","id":"32092c95-56ff-4573-bcd6-aaf56236a760","outputs":[{"output_type":"stream","name":"stdout","text":"[[ 780  572 1138 1133]]\nCPU times: user 1.52 ms, sys: 17 µs, total: 1.54 ms\nWall time: 747 µs\n"}],"execution_count":7},{"source":"## Speed with IndexIVFFlat (Faster, ~2000 training points )","metadata":{},"cell_type":"markdown","id":"9365001e-9923-423f-ba8e-174b8bd7141c"},{"source":"\nnlist = 50  # how many cells\nquantizer = faiss.IndexFlatL2(vector_dimension)\nindex = faiss.IndexIVFFlat(quantizer, vector_dimension, nlist)\nindex.train(vectors)  # train the index before adding vectors\nindex.add(vectors)\nindex.ntotal\n\nk = 4\n\n# Perform the search\ndistances, ann = index.search(search_vector, k=k)\n\n# Create a DataFrame with the distances and indices of the nearest neighbors\nresults = pd.DataFrame({'distances': distances[0], 'ann': ann[0]})\n\n# Merge the results with the original DataFrame to get the titles of the nearest neighbors\nmerge = pd.merge(results, df, left_on='ann', right_index=True)\n\n# Display the top results\nmerge.head()","metadata":{"executionCancelledAt":null,"executionTime":195,"lastExecutedAt":1715939035719,"lastExecutedByKernel":"56a34db2-4398-4bca-97e1-69d276c8e9d7","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"\nnlist = 50  # how many cells\nquantizer = faiss.IndexFlatL2(vector_dimension)\nindex = faiss.IndexIVFFlat(quantizer, vector_dimension, nlist)\nindex.train(vectors)  # train the index before adding vectors\nindex.add(vectors)\nindex.ntotal\n\nk = 4\n\n# Perform the search\ndistances, ann = index.search(search_vector, k=k)\n\n# Create a DataFrame with the distances and indices of the nearest neighbors\nresults = pd.DataFrame({'distances': distances[0], 'ann': ann[0]})\n\n# Merge the results with the original DataFrame to get the titles of the nearest neighbors\nmerge = pd.merge(results, df, left_on='ann', right_index=True)\n\n# Display the top results\nmerge.head()","outputsMetadata":{"0":{"height":171,"type":"dataFrame"}}},"cell_type":"code","id":"996e85b9-fdf3-4e85-8015-8d10b41c5d7d","outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"distances","type":"number"},{"name":"ann","type":"integer"},{"name":"Title","type":"string"},{"name":"Cleaned_Title","type":"string"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[0,1,2,3],"distances":[1.2001717091,1.2311756611,1.2491230965,1.2773137093],"ann":[169,167,172,74],"Title":["Director of Data Science","Director of Quantum Computing","Director of Nanotechnology","Chief Nanotechnology Officer"],"Cleaned_Title":["Director of Data Science","Director of Quantum Computing","Director of Nanotechnology","Chief Nanotechnology Officer"]}},"total_rows":4,"truncation_type":null},"text/plain":"   distances  ann                          Title                  Cleaned_Title\n0   1.200172  169       Director of Data Science       Director of Data Science\n1   1.231176  167  Director of Quantum Computing  Director of Quantum Computing\n2   1.249123  172     Director of Nanotechnology     Director of Nanotechnology\n3   1.277314   74   Chief Nanotechnology Officer   Chief Nanotechnology Officer","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>distances</th>\n      <th>ann</th>\n      <th>Title</th>\n      <th>Cleaned_Title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.200172</td>\n      <td>169</td>\n      <td>Director of Data Science</td>\n      <td>Director of Data Science</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.231176</td>\n      <td>167</td>\n      <td>Director of Quantum Computing</td>\n      <td>Director of Quantum Computing</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.249123</td>\n      <td>172</td>\n      <td>Director of Nanotechnology</td>\n      <td>Director of Nanotechnology</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.277314</td>\n      <td>74</td>\n      <td>Chief Nanotechnology Officer</td>\n      <td>Chief Nanotechnology Officer</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":17}],"execution_count":17},{"source":"%%time\nD, I = index.search(search_vector, k)  # search\nprint(I)","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1715938683855,"lastExecutedByKernel":"56a34db2-4398-4bca-97e1-69d276c8e9d7","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"%%time\nD, I = index.search(search_vector, k)  # search\nprint(I)","outputsMetadata":{"0":{"height":80,"type":"stream"}}},"cell_type":"code","id":"2f522f20-97dc-4ee8-a3db-7f8a7e71f178","outputs":[{"output_type":"stream","name":"stdout","text":"[[ 780  572 1138 1133]]\nCPU times: user 0 ns, sys: 1.63 ms, total: 1.63 ms\nWall time: 1 ms\n"}],"execution_count":9},{"source":"## Speed with IndexIVFPQ (fastest, with ~10000 training points)","metadata":{},"cell_type":"markdown","id":"4c26756e-20bf-4897-b647-635b4218862e"},{"source":"m = 8  # number of centroid IDs in final compressed vectors\nbits = 8 # number of bits in each centroid\n\nquantizer = faiss.IndexFlatL2(vector_dimension)  # we keep the same L2 distance flat index\nindex = faiss.IndexIVFPQ(quantizer, vector_dimension, nlist, m, bits)\nindex.train(vectors)\nindex.add(vectors)","metadata":{"executionCancelledAt":null,"executionTime":3137,"lastExecutedAt":1715938686992,"lastExecutedByKernel":"56a34db2-4398-4bca-97e1-69d276c8e9d7","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"m = 8  # number of centroid IDs in final compressed vectors\nbits = 8 # number of bits in each centroid\n\nquantizer = faiss.IndexFlatL2(vector_dimension)  # we keep the same L2 distance flat index\nindex = faiss.IndexIVFPQ(quantizer, vector_dimension, nlist, m, bits)\nindex.train(vectors)\nindex.add(vectors)","outputsMetadata":{"0":{"height":185,"type":"stream"}}},"cell_type":"code","id":"ba6236fa-8b3a-48c4-a293-8cc99a961608","outputs":[{"output_type":"stream","name":"stderr","text":"WARNING clustering 2259 points to 256 centroids: please provide at least 9984 training points\nWARNING clustering 2259 points to 256 centroids: please provide at least 9984 training points\nWARNING clustering 2259 points to 256 centroids: please provide at least 9984 training points\nWARNING clustering 2259 points to 256 centroids: please provide at least 9984 training points\nWARNING clustering 2259 points to 256 centroids: please provide at least 9984 training points\nWARNING clustering 2259 points to 256 centroids: please provide at least 9984 training points\nWARNING clustering 2259 points to 256 centroids: please provide at least 9984 training points\nWARNING clustering 2259 points to 256 centroids: please provide at least 9984 training points\n"}],"execution_count":10}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":5}